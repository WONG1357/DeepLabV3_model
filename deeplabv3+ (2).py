# -*- coding: utf-8 -*-
"""DeepLabV3+

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NjP9-VTlWoS_N5LIMKP0WzBVrR0YnOnM

# rectus femoris msucle
"""

# Step 1: Import Libraries and Mount Google Drive
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torchvision.models.segmentation import deeplabv3_resnet50
import numpy as np
import matplotlib.pyplot as plt
import random
from PIL import Image
import torchvision.transforms.functional as F
import os
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Step 2: Define Custom Dataset (Without Augmentation)
class UltrasoundNpyDataset(Dataset):
    def __init__(self, x_data, y_data, is_train=True):
        """
        Args:
            x_data (np.array): NumPy array of images (N, H, W, 1).
            y_data (np.array): NumPy array of masks (N, H, W, 1).
            is_train (bool): This parameter is kept for consistency but is no longer used
                             to apply augmentations.
        """
        self.x_data = x_data
        self.y_data = y_data
        self.is_train = is_train # Kept for API consistency

        # Image-only transform (normalization for RGB)
        self.image_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

    def __len__(self):
        return len(self.x_data)

    def __getitem__(self, idx):
        # Get raw numpy data
        image_np = self.x_data[idx]
        mask_np = self.y_data[idx]

        # Convert to (H, W, C) for PIL
        if image_np.shape[0] in [1, 3]:
            image_np = image_np.transpose(1, 2, 0)

        # Convert grayscale to RGB
        if image_np.shape[-1] == 1:
            image_np = np.repeat(image_np, 3, axis=-1)

        # Squeeze mask if needed (N, H, W, 1) -> (H, W)
        if len(mask_np.shape) == 3 and mask_np.shape[-1] == 1:
            mask_np = mask_np.squeeze(-1)

        # Convert to PIL Images
        image = Image.fromarray((image_np * 255).astype(np.uint8))
        mask = Image.fromarray(mask_np.astype(np.uint8))

        # --- ESSENTIAL TRANSFORMATION: RESIZING ---
        # This is kept as the model requires a fixed input size.
        image = F.resize(image, (256, 256))
        mask = F.resize(mask, (256, 256), interpolation=Image.NEAREST)

        # Convert to tensors
        image = self.image_transform(image)
        mask = torch.from_numpy(np.array(mask)).long()

        return image, mask

# Step 3: Load Data
base_path = '/content/drive/MyDrive/intern RF transverse latest file/'
train_image_file = os.path.join(base_path, 'X_train.npy')
train_mask_file = os.path.join(base_path, 'y_train.npy')
val_image_file = os.path.join(base_path, 'X_val.npy')
val_mask_file = os.path.join(base_path, 'y_val.npy')
test_image_file = os.path.join(base_path, 'X_test.npy')
test_mask_file = os.path.join(base_path, 'y_test.npy')

# Load .npy files
try:
    x_train = np.load(train_image_file)
    y_train = np.load(train_mask_file)
    x_val = np.load(val_image_file)
    y_val = np.load(val_mask_file)
    x_test = np.load(test_image_file)
    y_test = np.load(test_mask_file)
except Exception as e:
    print(f"Error loading .npy files: {e}")
    raise

print("Train shapes:", x_train.shape, y_train.shape, np.unique(y_train))
print("Val shapes:", x_val.shape, y_val.shape, np.unique(y_val))
print("Test shapes:", x_test.shape, y_test.shape, np.unique(y_test))

# Create datasets
train_dataset = UltrasoundNpyDataset(x_train, y_train, is_train=True)
val_dataset = UltrasoundNpyDataset(x_val, y_val, is_train=False)
test_dataset = UltrasoundNpyDataset(x_test, y_test, is_train=False)

# Create DataLoaders with drop_last=True to avoid single-sample batches
batch_size = 4
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)

# Verify batch shapes
try:
    images, masks = next(iter(train_dataloader))
    print("Batch shapes - Images:", images.shape, "Masks:", masks.shape)
except Exception as e:
    print(f"Error in DataLoader: {e}")
    raise

# Step 4: Define Dice Score
def calculate_dice(pred, target, num_classes=2, smooth=1e-6):
    pred = pred.argmax(dim=1)  # Convert logits to class predictions
    dice_scores = []
    for batch_idx in range(pred.size(0)):
        pred_flat = pred[batch_idx].flatten()
        target_flat = target[batch_idx].flatten()
        intersection = ((pred_flat == 1) & (target_flat == 1)).sum().item()
        pred_sum = (pred_flat == 1).sum().item()
        target_sum = (target_flat == 1).sum().item()
        # Handle edge case where both prediction and target are empty
        if pred_sum + target_sum == 0:
            dice = 1.0  # Perfect score if both are empty
        else:
            dice = (2 * intersection + smooth) / (pred_sum + target_sum + smooth)
        dice_scores.append(dice)
    return sum(dice_scores) / len(dice_scores) if dice_scores else 0.0

# Step 5: Initialize Model, Loss, and Optimizer
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = deeplabv3_resnet50(weights=None, num_classes=2)  # Untrained model
model = model.to(device)
criterion = torch.nn.CrossEntropyLoss(ignore_index=255)
optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)

# Step 6: Training Loop
num_epochs = 50
best_dice = 0.0
best_model_path = '/content/drive/MyDrive/internship models/deeplabv3+ resnet 50/rectus femoris/deeplabv3plus_resnet50_best.pth'

# Create directory for saving models
os.makedirs(os.path.dirname(best_model_path), exist_ok=True)

model.train()
for epoch in range(num_epochs):
    running_loss = 0.0
    for images, masks in train_dataloader:
        images = images.to(device)
        masks = masks.to(device)
        optimizer.zero_grad()
        outputs = model(images)['out']
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    train_loss = running_loss / max(len(train_dataloader), 1)  # Avoid division by zero

    # Validation
    model.eval()
    val_loss = 0.0
    val_dice_scores = []
    with torch.no_grad():
        for images, masks in val_dataloader:
            images = images.to(device)
            masks = masks.to(device)
            outputs = model(images)['out']
            val_loss += criterion(outputs, masks).item()
            dice_score = calculate_dice(outputs, masks)
            val_dice_scores.append(dice_score)

    val_loss = val_loss / max(len(val_dataloader), 1)  # Avoid division by zero
    val_dice = sum(val_dice_scores) / len(val_dice_scores) if val_dice_scores else 0.0

    # Save best model based on Dice score
    if val_dice > best_dice:
        best_dice = val_dice
        torch.save(model.state_dict(), best_model_path)
        print(f"Saved best model with Dice: {best_dice:.4f} at epoch {epoch+1}")

    print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}")
    model.train()

# Step 7: Visualize Predictions
model.eval()
plt.figure(figsize=(15, 5))
val_indices = random.sample(range(len(val_dataset)), min(3, len(val_dataset)))
for i, idx in enumerate(val_indices):
    image, mask = val_dataset[idx]
    image_tensor = image.unsqueeze(0).to(device)
    with torch.no_grad():
        output = model(image_tensor)['out']
        pred = output.argmax(dim=1).cpu().numpy()[0]

    # Denormalize image for display
    image_np = image.permute(1, 2, 0).numpy()
    image_np = (image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))
    image_np = (image_np * 255).astype(np.uint8)

    # Plot
    plt.subplot(3, 3, i*3 + 1)
    plt.imshow(image_np)
    plt.title('Input Image')
    plt.axis('off')

    plt.subplot(3, 3, i*3 + 2)
    plt.imshow(mask.numpy(), cmap='gray')
    plt.title('Ground Truth')
    plt.axis('off')

    plt.subplot(3, 3, i*3 + 3)
    plt.imshow(pred, cmap='gray')
    plt.title('Prediction')
    plt.axis('off')

plt.tight_layout()
plt.show()

# Step 8: Evaluate on Test Set
model.eval()
test_dice_scores = []
with torch.no_grad():
    for images, masks in test_dataloader:
        images = images.to(device)
        masks = masks.to(device)
        outputs = model(images)['out']
        dice_score = calculate_dice(outputs, masks)
        test_dice_scores.append(dice_score)

test_dice = sum(test_dice_scores) / len(test_dice_scores) if test_dice_scores else 0.0
print(f"Test Dice Score: {test_dice:.4f}")

# Step 9: Evaluate and Save Predictions for Train and Test Sets
from scipy import ndimage
import os
from tqdm import tqdm

# --- 9.1: Define Post-Processing Function ---
def post_process_mask(mask):
    """Applies post-processing to a binary segmentation mask."""
    labels, num_features = ndimage.label(mask)
    if num_features == 0:
        return mask
    component_sizes = np.bincount(labels.ravel())
    if len(component_sizes) > 1:
        largest_component_label = component_sizes[1:].argmax() + 1
        processed_mask = (labels == largest_component_label)
        processed_mask = ndimage.binary_fill_holes(processed_mask)
        return processed_mask.astype(np.uint8)
    return mask

# --- 9.2: Load the Best Model ---
print("Loading the best model for evaluation...")
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = deeplabv3_resnet50(weights=None, num_classes=2)
model_path = '/content/drive/MyDrive/internship models/deeplabv3+ resnet 50/rectus femoris/deeplabv3plus_resnet50_best.pth'
model.load_state_dict(torch.load(model_path, map_location=DEVICE))
model = model.to(DEVICE)
model.eval()

# --- 9.3: Define Save Directories and Visualization Helper ---
BASE_SAVE_DIR = '/content/drive/MyDrive/internship models/deeplabv3+ resnet 50/rectus femoris/segmentation_results_with_preprocessing'
TRAIN_SAVE_DIR = os.path.join(BASE_SAVE_DIR, 'train_set_predictions')
TEST_SAVE_DIR = os.path.join(BASE_SAVE_DIR, 'test_set_predictions')

os.makedirs(TRAIN_SAVE_DIR, exist_ok=True)
os.makedirs(TEST_SAVE_DIR, exist_ok=True)

print(f"Train set predictions will be saved to: {TRAIN_SAVE_DIR}")
print(f"Test set predictions will be saved to: {TEST_SAVE_DIR}")

def visualize_and_save(processed_img, gt_mask, pred_raw, pred_post, save_path, title):
    """Helper function to plot and save comparison images."""
    if processed_img.shape[0] == 3:  # RGB
        image_np = processed_img.cpu().permute(1, 2, 0).numpy()
        image_np = (image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))
        image_np = (image_np * 255).astype(np.uint8)
    else:  # Grayscale (shouldn't occur with current dataset)
        image_np = processed_img.cpu().squeeze(0).numpy() * 255

    fig, axes = plt.subplots(1, 4, figsize=(20, 5))
    axes[0].imshow(image_np)
    axes[0].set_title("Input Image")
    axes[0].axis('off')
    axes[1].imshow(gt_mask, cmap='gray')
    axes[1].set_title("Ground Truth")
    axes[1].axis('off')
    axes[2].imshow(pred_raw, cmap='gray')
    axes[2].set_title("Raw Prediction")
    axes[2].axis('off')
    axes[3].imshow(pred_post, cmap='gray')
    axes[3].set_title("Post-Processed Prediction")
    axes[3].axis('off')
    plt.suptitle(title, fontsize=16)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close(fig)

# --- 9.4: Run Evaluation on the ENTIRE Test Set & Save ALL Predictions ---
print("\n--- Evaluating ENTIRE Test Set and Saving All Predictions ---")
total_dice_before = 0
total_dice_after = 0
num_samples_test = 0
smooth = 1e-6

with torch.no_grad():
    for i, (images, gt_masks) in enumerate(tqdm(test_dataloader, desc="Testing and Saving")):
        images = images.to(DEVICE)
        gt_masks_np = gt_masks.cpu().numpy()

        outputs = model(images)['out']
        preds_raw = outputs.argmax(dim=1).cpu().numpy()
        preds_post = np.array([post_process_mask(pred) for pred in preds_raw])

        for j in range(images.shape[0]):
            image_idx = i * test_dataloader.batch_size + j

            gt = np.squeeze(gt_masks_np[j]).flatten()
            pred_before = np.squeeze(preds_raw[j]).flatten()
            pred_after = np.squeeze(preds_post[j]).flatten()

            intersection_before = (pred_before * gt).sum()
            total_dice_before += (2. * intersection_before + smooth) / (pred_before.sum() + gt.sum() + smooth)

            intersection_after = (pred_after * gt).sum()
            total_dice_after += (2. * intersection_after + smooth) / (pred_after.sum() + gt.sum() + smooth)

            num_samples_test += 1

            save_path = os.path.join(TEST_SAVE_DIR, f"test_prediction_{image_idx+1}.png")
            visualize_and_save(
                processed_img=images[j],
                gt_mask=gt_masks_np[j],
                pred_raw=preds_raw[j],
                pred_post=preds_post[j],
                save_path=save_path,
                title=f"Test Set - Prediction {image_idx+1}"
            )

# --- 9.5: Print Final Test Results ---
avg_dice_before_test = total_dice_before / num_samples_test
avg_dice_after_test = total_dice_after / num_samples_test
print(f"\n--- Test Set Evaluation Complete ---")
print(f"Total Test Images Processed: {num_samples_test}")
print(f"Average Dice (Before Post-Processing): {avg_dice_before_test:.4f}")
print(f"Average Dice (After Post-Processing):  {avg_dice_after_test:.4f}")

# --- 9.6: Run Evaluation on the ENTIRE Train Set & Save ALL Predictions ---
print("\n--- Evaluating ENTIRE Train Set and Saving All Predictions ---")
num_samples_train = 0
total_dice_before_train = 0
total_dice_after_train = 0

with torch.no_grad():
    for i, (images, gt_masks) in enumerate(tqdm(train_dataloader, desc="Training Set Prediction")):
        images = images.to(DEVICE)
        gt_masks_np = gt_masks.cpu().numpy()

        outputs = model(images)['out']
        preds_raw = outputs.argmax(dim=1).cpu().numpy()
        preds_post = np.array([post_process_mask(pred) for pred in preds_raw])

        for j in range(images.shape[0]):
            image_idx = i * train_dataloader.batch_size + j

            gt = np.squeeze(gt_masks_np[j]).flatten()
            pred_before = np.squeeze(preds_raw[j]).flatten()
            pred_after = np.squeeze(preds_post[j]).flatten()

            intersection_before = (pred_before * gt).sum()
            total_dice_before_train += (2. * intersection_before + smooth) / (pred_before.sum() + gt.sum() + smooth)

            intersection_after = (pred_after * gt).sum()
            total_dice_after_train += (2. * intersection_after + smooth) / (pred_after.sum() + gt.sum() + smooth)

            num_samples_train += 1

            save_path = os.path.join(TRAIN_SAVE_DIR, f"train_prediction_{image_idx+1}.png")
            visualize_and_save(
                processed_img=images[j],
                gt_mask=gt_masks_np[j],
                pred_raw=preds_raw[j],
                pred_post=preds_post[j],
                save_path=save_path,
                title=f"Train Set - Prediction {image_idx+1}"
            )

# --- 9.7: Print Final Train Results ---
avg_dice_before_train = total_dice_before_train / num_samples_train
avg_dice_after_train = total_dice_after_train / num_samples_train
print(f"\n--- Train Set Evaluation Complete ---")
print(f"Total Train Images Processed: {num_samples_train}")
print(f"Average Dice (Before Post-Processing): {avg_dice_before_train:.4f}")
print(f"Average Dice (After Post-Processing):  {avg_dice_after_train:.4f}")
print(f"All predictions saved successfully to Google Drive.")

"""# vastus medialis muscle"""

# Step 2: Define Custom Dataset (Without Augmentation)
class UltrasoundNpyDataset(Dataset):
    def __init__(self, x_data, y_data, is_train=True):
        """
        Args:
            x_data (np.array): NumPy array of images (N, H, W, 1).
            y_data (np.array): NumPy array of masks (N, H, W, 1).
            is_train (bool): This parameter is kept for consistency but is no longer used
                             to apply augmentations.
        """
        self.x_data = x_data
        self.y_data = y_data
        self.is_train = is_train # Kept for API consistency

        # Image-only transform (normalization for RGB)
        self.image_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

    def __len__(self):
        return len(self.x_data)

    def __getitem__(self, idx):
        # Get raw numpy data
        image_np = self.x_data[idx]
        mask_np = self.y_data[idx]

        # Convert to (H, W, C) for PIL
        if image_np.shape[0] in [1, 3]:
            image_np = image_np.transpose(1, 2, 0)

        # Convert grayscale to RGB
        if image_np.shape[-1] == 1:
            image_np = np.repeat(image_np, 3, axis=-1)

        # Squeeze mask if needed (N, H, W, 1) -> (H, W)
        if len(mask_np.shape) == 3 and mask_np.shape[-1] == 1:
            mask_np = mask_np.squeeze(-1)

        # Convert to PIL Images
        image = Image.fromarray((image_np * 255).astype(np.uint8))
        mask = Image.fromarray(mask_np.astype(np.uint8))

        # --- ESSENTIAL TRANSFORMATION: RESIZING ---
        # This is kept as the model requires a fixed input size.
        image = F.resize(image, (256, 256))
        mask = F.resize(mask, (256, 256), interpolation=Image.NEAREST)

        # Convert to tensors
        image = self.image_transform(image)
        mask = torch.from_numpy(np.array(mask)).long()

        return image, mask

# Step 3: Load Data
base_path = '/content/drive/MyDrive/intern RF longitudinal latest file/'
train_image_file = os.path.join(base_path, 'X_train.npy')
train_mask_file = os.path.join(base_path, 'y_train.npy')
val_image_file = os.path.join(base_path, 'X_val.npy')
val_mask_file = os.path.join(base_path, 'y_val.npy')
test_image_file = os.path.join(base_path, 'X_test.npy')
test_mask_file = os.path.join(base_path, 'y_test.npy')

# Load .npy files
try:
    x_train = np.load(train_image_file)
    y_train = np.load(train_mask_file)
    x_val = np.load(val_image_file)
    y_val = np.load(val_mask_file)
    x_test = np.load(test_image_file)
    y_test = np.load(test_mask_file)
except Exception as e:
    print(f"Error loading .npy files: {e}")
    raise

print("Train shapes:", x_train.shape, y_train.shape, np.unique(y_train))
print("Val shapes:", x_val.shape, y_val.shape, np.unique(y_val))
print("Test shapes:", x_test.shape, y_test.shape, np.unique(y_test))

# Create datasets
train_dataset = UltrasoundNpyDataset(x_train, y_train, is_train=True)
val_dataset = UltrasoundNpyDataset(x_val, y_val, is_train=False)
test_dataset = UltrasoundNpyDataset(x_test, y_test, is_train=False)

# Create DataLoaders with drop_last=True to avoid single-sample batches
batch_size = 4
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)

# Verify batch shapes
try:
    images, masks = next(iter(train_dataloader))
    print("Batch shapes - Images:", images.shape, "Masks:", masks.shape)
except Exception as e:
    print(f"Error in DataLoader: {e}")
    raise

# Step 4: Define Dice Score
def calculate_dice(pred, target, num_classes=2, smooth=1e-6):
    pred = pred.argmax(dim=1)  # Convert logits to class predictions
    dice_scores = []
    for batch_idx in range(pred.size(0)):
        pred_flat = pred[batch_idx].flatten()
        target_flat = target[batch_idx].flatten()
        intersection = ((pred_flat == 1) & (target_flat == 1)).sum().item()
        pred_sum = (pred_flat == 1).sum().item()
        target_sum = (target_flat == 1).sum().item()
        # Handle edge case where both prediction and target are empty
        if pred_sum + target_sum == 0:
            dice = 1.0  # Perfect score if both are empty
        else:
            dice = (2 * intersection + smooth) / (pred_sum + target_sum + smooth)
        dice_scores.append(dice)
    return sum(dice_scores) / len(dice_scores) if dice_scores else 0.0

# Step 5: Initialize Model, Loss, and Optimizer
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = deeplabv3_resnet50(weights=None, num_classes=2)  # Untrained model
model = model.to(device)
criterion = torch.nn.CrossEntropyLoss(ignore_index=255)
optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)

# Step 6: Training Loop
num_epochs = 50
best_dice = 0.0
best_model_path = '/content/drive/MyDrive/internship models/deeplabv3+ resnet 50/vastus medialis/deeplabv3plus_resnet50_best.pth'

# Create directory for saving models
os.makedirs(os.path.dirname(best_model_path), exist_ok=True)

model.train()
for epoch in range(num_epochs):
    running_loss = 0.0
    for images, masks in train_dataloader:
        images = images.to(device)
        masks = masks.to(device)
        optimizer.zero_grad()
        outputs = model(images)['out']
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    train_loss = running_loss / max(len(train_dataloader), 1)  # Avoid division by zero

    # Validation
    model.eval()
    val_loss = 0.0
    val_dice_scores = []
    with torch.no_grad():
        for images, masks in val_dataloader:
            images = images.to(device)
            masks = masks.to(device)
            outputs = model(images)['out']
            val_loss += criterion(outputs, masks).item()
            dice_score = calculate_dice(outputs, masks)
            val_dice_scores.append(dice_score)

    val_loss = val_loss / max(len(val_dataloader), 1)  # Avoid division by zero
    val_dice = sum(val_dice_scores) / len(val_dice_scores) if val_dice_scores else 0.0

    # Save best model based on Dice score
    if val_dice > best_dice:
        best_dice = val_dice
        torch.save(model.state_dict(), best_model_path)
        print(f"Saved best model with Dice: {best_dice:.4f} at epoch {epoch+1}")

    print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}")
    model.train()

# Step 10: Evaluate and Save Predictions for Train and Test Sets
from scipy import ndimage
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
from PIL import Image
import torch
import numpy as np

# --- 10.1: Define Post-Processing Function ---
def post_process_mask(mask):
    """Applies post-processing to a binary segmentation mask."""
    labels, num_features = ndimage.label(mask)
    if num_features == 0:
        return mask
    component_sizes = np.bincount(labels.ravel())
    if len(component_sizes) > 1:
        largest_component_label = component_sizes[1:].argmax() + 1
        processed_mask = (labels == largest_component_label)
        processed_mask = ndimage.binary_fill_holes(processed_mask)
        return processed_mask.astype(np.uint8)
    return mask

# --- 10.2: Load the Best Model ---
print("Loading the best model for evaluation...")
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = deeplabv3_resnet50(weights=None, num_classes=2)
model_path = '/content/drive/MyDrive/internship models/deeplabv3+ resnet 50/vastus medialis/deeplabv3plus_resnet50_best.pth'
model.load_state_dict(torch.load(model_path, map_location=DEVICE))
model = model.to(DEVICE)
model.eval()

# --- 10.3: Define Save Directories and Visualization Helper ---
BASE_SAVE_DIR = '/content/drive/MyDrive/internship models/deeplabv3+ resnet 50/vastus medialis/segmentation_results_with_preprocessing'
TRAIN_SAVE_DIR = os.path.join(BASE_SAVE_DIR, 'train_set_predictions')
TEST_SAVE_DIR = os.path.join(BASE_SAVE_DIR, 'test_set_predictions')

os.makedirs(TRAIN_SAVE_DIR, exist_ok=True)
os.makedirs(TEST_SAVE_DIR, exist_ok=True)

print(f"Train set predictions will be saved to: {TRAIN_SAVE_DIR}")
print(f"Test set predictions will be saved to: {TEST_SAVE_DIR}")

def visualize_and_save(processed_img, gt_mask, pred_raw, pred_post, save_path, title):
    """Helper function to plot and save comparison images."""
    if processed_img.shape[0] == 3:  # RGB
        image_np = processed_img.cpu().permute(1, 2, 0).numpy()
        image_np = (image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406]))
        image_np = (image_np * 255).astype(np.uint8)
    else:  # Grayscale (shouldn't occur with current dataset)
        image_np = processed_img.cpu().squeeze(0).numpy() * 255

    fig, axes = plt.subplots(1, 4, figsize=(20, 5))
    axes[0].imshow(image_np)
    axes[0].set_title("Input Image")
    axes[0].axis('off')
    axes[1].imshow(gt_mask, cmap='gray')
    axes[1].set_title("Ground Truth")
    axes[1].axis('off')
    axes[2].imshow(pred_raw, cmap='gray')
    axes[2].set_title("Raw Prediction")
    axes[2].axis('off')
    axes[3].imshow(pred_post, cmap='gray')
    axes[3].set_title("Post-Processed Prediction")
    axes[3].axis('off')
    plt.suptitle(title, fontsize=16)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close(fig)

# --- 10.4: Run Evaluation on the ENTIRE Test Set & Save ALL Predictions ---
print("\n--- Evaluating ENTIRE Test Set and Saving All Predictions ---")
total_dice_before = 0
total_dice_after = 0
num_samples_test = 0
smooth = 1e-6

with torch.no_grad():
    for i, (images, gt_masks) in enumerate(tqdm(test_dataloader, desc="Testing and Saving")):
        images = images.to(DEVICE)
        gt_masks_np = gt_masks.cpu().numpy()

        outputs = model(images)['out']
        preds_raw = outputs.argmax(dim=1).cpu().numpy()
        preds_post = np.array([post_process_mask(pred) for pred in preds_raw])

        for j in range(images.shape[0]):
            image_idx = i * test_dataloader.batch_size + j

            gt = np.squeeze(gt_masks_np[j]).flatten()
            pred_before = np.squeeze(preds_raw[j]).flatten()
            pred_after = np.squeeze(preds_post[j]).flatten()

            intersection_before = (pred_before * gt).sum()
            total_dice_before += (2. * intersection_before + smooth) / (pred_before.sum() + gt.sum() + smooth)

            intersection_after = (pred_after * gt).sum()
            total_dice_after += (2. * intersection_after + smooth) / (pred_after.sum() + gt.sum() + smooth)

            num_samples_test += 1

            save_path = os.path.join(TEST_SAVE_DIR, f"test_prediction_{image_idx+1}.png")
            visualize_and_save(
                processed_img=images[j],
                gt_mask=gt_masks_np[j],
                pred_raw=preds_raw[j],
                pred_post=preds_post[j],
                save_path=save_path,
                title=f"Test Set - Prediction {image_idx+1}"
            )

# --- 10.5: Print Final Test Results ---
avg_dice_before_test = total_dice_before / num_samples_test
avg_dice_after_test = total_dice_after / num_samples_test
print(f"\n--- Test Set Evaluation Complete ---")
print(f"Total Test Images Processed: {num_samples_test}")
print(f"Average Dice (Before Post-Processing): {avg_dice_before_test:.4f}")
print(f"Average Dice (After Post-Processing):  {avg_dice_after_test:.4f}")

# --- 10.6: Run Evaluation on the ENTIRE Train Set & Save ALL Predictions ---
print("\n--- Evaluating ENTIRE Train Set and Saving All Predictions ---")
num_samples_train = 0
total_dice_before_train = 0
total_dice_after_train = 0

with torch.no_grad():
    for i, (images, gt_masks) in enumerate(tqdm(train_dataloader, desc="Training Set Prediction")):
        images = images.to(DEVICE)
        gt_masks_np = gt_masks.cpu().numpy()

        outputs = model(images)['out']
        preds_raw = outputs.argmax(dim=1).cpu().numpy()
        preds_post = np.array([post_process_mask(pred) for pred in preds_raw])

        for j in range(images.shape[0]):
            image_idx = i * train_dataloader.batch_size + j

            gt = np.squeeze(gt_masks_np[j]).flatten()
            pred_before = np.squeeze(preds_raw[j]).flatten()
            pred_after = np.squeeze(preds_post[j]).flatten()

            intersection_before = (pred_before * gt).sum()
            total_dice_before_train += (2. * intersection_before + smooth) / (pred_before.sum() + gt.sum() + smooth)

            intersection_after = (pred_after * gt).sum()
            total_dice_after_train += (2. * intersection_after + smooth) / (pred_after.sum() + gt.sum() + smooth)

            num_samples_train += 1

            save_path = os.path.join(TRAIN_SAVE_DIR, f"train_prediction_{image_idx+1}.png")
            visualize_and_save(
                processed_img=images[j],
                gt_mask=gt_masks_np[j],
                pred_raw=preds_raw[j],
                pred_post=preds_post[j],
                save_path=save_path,
                title=f"Train Set - Prediction {image_idx+1}"
            )

# --- 10.7: Print Final Train Results ---
avg_dice_before_train = total_dice_before_train / num_samples_train
avg_dice_after_train = total_dice_after_train / num_samples_train
print(f"\n--- Train Set Evaluation Complete ---")
print(f"Total Train Images Processed: {num_samples_train}")
print(f"Average Dice (Before Post-Processing): {avg_dice_before_train:.4f}")
print(f"Average Dice (After Post-Processing):  {avg_dice_after_train:.4f}")
print(f"All predictions saved successfully to Google Drive.")